root@7686e42ed424:/home/workspace/ImageClassifier# python train.py data_dir=/home/workspace/ImageClassifier/flowers --arch vgg16 --save_dir /home/workspace/ImageClassifier --epochs 15 --learning_rate 0.0001 --dropout_p 0.5 --hidden_units 4096 2048 1024 512 --gpu
Get CLI arguments ...
Load data ...
Load mapping of categories to label names ...
Create model ...
Define device ...
*****
Model
*****
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (fc1): Linear(in_features=25088, out_features=4096, bias=True)
    (relu1): ReLU()
    (dropout1): Dropout(p=0.5)
    (fc2): Linear(in_features=4096, out_features=2048, bias=True)
    (relu2): ReLU()
    (dropout2): Dropout(p=0.5)
    (fc3): Linear(in_features=2048, out_features=1024, bias=True)
    (relu3): ReLU()
    (dropout3): Dropout(p=0.5)
    (fc4): Linear(in_features=1024, out_features=512, bias=True)
    (relu4): ReLU()
    (dropout4): Dropout(p=0.5)
    (fc5): Linear(in_features=512, out_features=102, bias=True)
    (out_log_softmax): LogSoftmax()
  )
)
****************
Model parameters
****************
data_dir: /data/flowers
save_dir: /home/workspace/ImageClassifier
arch: vgg16
learning_rate: 0.0001
epochs: 15
hidden_units: [4096, 2048, 1024, 512]
gpu: True
batch_size: 32
dropout_p: 0.5
target_mapping: cat_to_name.json
train_datasets_class_to_idx: {'1': 0, '10': 1, '100': 2, '101': 3, '102': 4, '11': 5, '12': 6, '13': 7, '14': 8, '15': 9, '16': 10, '17': 11, '18': 12, '19': 13, '2': 14, '20': 15, '21': 16, '22': 17, '23': 18, '24': 19, '25': 20, '26': 21, '27': 22, '28': 23, '29': 24, '3': 25, '30': 26, '31': 27, '32': 28, '33': 29, '34': 30, '35': 31, '36': 32, '37': 33, '38': 34, '39': 35, '4': 36, '40': 37, '41': 38, '42': 39, '43': 40, '44': 41, '45': 42, '46': 43, '47': 44, '48': 45, '49': 46, '5': 47, '50': 48, '51': 49, '52': 50, '53': 51, '54': 52, '55': 53, '56': 54, '57': 55, '58': 56, '59': 57, '6': 58, '60': 59, '61': 60, '62': 61, '63': 62, '64': 63, '65': 64, '66': 65, '67': 66, '68': 67, '69': 68, '7': 69, '70': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '8': 80, '80': 81, '81': 82, '82': 83, '83': 84, '84': 85, '85': 86, '86': 87, '87': 88, '88': 89, '89': 90, '9': 91, '90': 92, '91': 93, '92': 94, '93': 95, '94': 96, '95': 97, '96': 98, '97': 99, '98': 100, '99': 101}
no_records_train: 6552
no_records_valid: 818
no_records_test: 819
output_size: 102
output_function: LogSoftmax
loss_function: NLLLoss
optimizer: Adam
'state_dict' key does not exist
Start training inclusive validation ...
***************************
Epoch 1/15
----
Processed 51 training batches with 1632 processed images
Training loss: 4.59491470748303
Validation loss: 4.500361809363732
Validation accuracy: 0.040865384615384616
----
Processed 102 training batches with 3264 processed images
Training loss: 4.546064264634076
Validation loss: 4.362962777797993
Validation accuracy: 0.046875
----
Processed 153 training batches with 4896 processed images
Training loss: 4.4313536687614095
Validation loss: 3.8026732160494876
Validation accuracy: 0.14783653846153846
----
Processed 204 training batches with 6528 processed images
Training loss: 4.229679708387337
Validation loss: 2.9583505116976223
Validation accuracy: 0.2704326923076923
***************************
Epoch 2/15
----
Processed 51 training batches with 1632 processed images
Training loss: 3.733014887454463
Validation loss: 2.9325796503287096
Validation accuracy: 0.28365384615384615
----
Processed 102 training batches with 3264 processed images
Training loss: 3.2195002424950694
Validation loss: 2.3085682713068447
Validation accuracy: 0.38915598292190295
----
Processed 153 training batches with 4896 processed images
Training loss: 2.9012267192204795
Validation loss: 1.8881740925403743
Validation accuracy: 0.4813034190581395
----
Processed 204 training batches with 6528 processed images
Training loss: 2.6657978383933796
Validation loss: 1.552226362320093
Validation accuracy: 0.5520833340974954
***************************
Epoch 3/15
----
Processed 51 training batches with 1632 processed images
Training loss: 3.0067728594237684
Validation loss: 1.898230282159952
Validation accuracy: 0.5016025642936046
----
Processed 102 training batches with 3264 processed images
Training loss: 2.4255630070087957
Validation loss: 1.3242042523164015
Validation accuracy: 0.6063034190581396
----
Processed 153 training batches with 4896 processed images
Training loss: 2.147207491538104
Validation loss: 1.2139138671068044
Validation accuracy: 0.6527777772683364
----
Processed 204 training batches with 6528 processed images
Training loss: 1.970130563951006
Validation loss: 1.1003437472077517
Validation accuracy: 0.6762820505178891
***************************
Epoch 4/15
----
Processed 51 training batches with 1632 processed images
Training loss: 2.6435624150668873
Validation loss: 1.442809814443955
Validation accuracy: 0.6123130344427549
----
Processed 102 training batches with 3264 processed images
Training loss: 2.040945113873949
Validation loss: 1.0652742374401827
Validation accuracy: 0.6826923076923077
----
Processed 153 training batches with 4896 processed images
Training loss: 1.7946316782945122
Validation loss: 0.9131407795044092
Validation accuracy: 0.736378204364043
----
Processed 204 training batches with 6528 processed images
Training loss: 1.64166083873487
Validation loss: 0.8894801770265286
Validation accuracy: 0.7414529919624329
***************************
Epoch 5/15
----
Processed 51 training batches with 1632 processed images
Training loss: 2.265892664591471
Validation loss: 1.1535956911169565
Validation accuracy: 0.698985042480322
----
Processed 102 training batches with 3264 processed images
Training loss: 1.7627898805281694
Validation loss: 0.8621404503400509
Validation accuracy: 0.7510683765778174
----
Processed 153 training batches with 4896 processed images
Training loss: 1.547591401860605
Validation loss: 0.8603365037303704
Validation accuracy: 0.7470619655572451
----
Processed 204 training batches with 6528 processed images
Training loss: 1.4197051247545318
Validation loss: 0.8499858333514287
Validation accuracy: 0.7724358966717353
***************************
Epoch 6/15
----
Processed 51 training batches with 1632 processed images
Training loss: 2.0358908363417085
Validation loss: 1.0125411003828049
Validation accuracy: 0.7267628197486584
----
Processed 102 training batches with 3264 processed images
Training loss: 1.5341287789975895
Validation loss: 0.7702570712337127
Validation accuracy: 0.7841880344427549
----
Processed 153 training batches with 4896 processed images
Training loss: 1.3604416759575115
Validation loss: 0.7752580849023966
Validation accuracy: 0.7856570505178891
----
Processed 204 training batches with 6528 processed images
Training loss: 1.2725832183279244
Validation loss: 0.7202738769925557
Validation accuracy: 0.8066239311144903
***************************
Epoch 7/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.9168896417991788
Validation loss: 0.8513424270428144
Validation accuracy: 0.7784455120563507
----
Processed 102 training batches with 3264 processed images
Training loss: 1.4353473104682624
Validation loss: 0.7111156410895861
Validation accuracy: 0.8000801274409661
----
Processed 153 training batches with 4896 processed images
Training loss: 1.2708175271944282
Validation loss: 0.7532810024344004
Validation accuracy: 0.7904647428255814
----
Processed 204 training batches with 6528 processed images
Training loss: 1.1798016893513061
Validation loss: 0.6496558177929658
Validation accuracy: 0.8169070505178891
***************************
Epoch 8/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.7669399298873603
Validation loss: 0.847319555397217
Validation accuracy: 0.7883279919624329
----
Processed 102 training batches with 3264 processed images
Training loss: 1.351169639650513
Validation loss: 0.6526833778390517
Validation accuracy: 0.8229166659025046
----
Processed 153 training batches with 4896 processed images
Training loss: 1.193838669388902
Validation loss: 0.6721410588003122
Validation accuracy: 0.8157051274409661
----
Processed 204 training batches with 6528 processed images
Training loss: 1.1058728900902413
Validation loss: 0.5919384916241353
Validation accuracy: 0.8400106842701252
***************************
Epoch 9/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.6292171314650892
Validation loss: 0.7089520277312169
Validation accuracy: 0.8181089735948123
----
Processed 102 training batches with 3264 processed images
Training loss: 1.2376317586384566
Validation loss: 0.6102693109558179
Validation accuracy: 0.8337339735948123
----
Processed 153 training batches with 4896 processed images
Training loss: 1.0873058225983887
Validation loss: 0.5842550849685302
Validation accuracy: 0.8349358966717353
----
Processed 204 training batches with 6528 processed images
Training loss: 1.0081326437054896
Validation loss: 0.57128750704802
Validation accuracy: 0.8361378197486584
***************************
Epoch 10/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.551863874874863
Validation loss: 0.7024324057767024
Validation accuracy: 0.814503204364043
----
Processed 102 training batches with 3264 processed images
Training loss: 1.1758716027526295
Validation loss: 0.5568964888270085
Validation accuracy: 0.8421474351332738
----
Processed 153 training batches with 4896 processed images
Training loss: 1.0202518919714136
Validation loss: 0.6136713142578418
Validation accuracy: 0.8337339735948123
----
Processed 204 training batches with 6528 processed images
Training loss: 0.9594340748062321
Validation loss: 0.6221431820438459
Validation accuracy: 0.8325320505178891
***************************
Epoch 11/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.5100066159285752
Validation loss: 0.6577421954044929
Validation accuracy: 0.8400106842701252
----
Processed 102 training batches with 3264 processed images
Training loss: 1.1417199370323443
Validation loss: 0.5511577983315175
Validation accuracy: 0.8493589735948123
----
Processed 153 training batches with 4896 processed images
Training loss: 1.0025196808810328
Validation loss: 0.5471881507680967
Validation accuracy: 0.84455128128712
----
Processed 204 training batches with 6528 processed images
Training loss: 0.9344212775867359
Validation loss: 0.48804531590296674
Validation accuracy: 0.86017628128712
***************************
Epoch 12/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.4132677912712097
Validation loss: 0.615894709355556
Validation accuracy: 0.833466880596601
----
Processed 102 training batches with 3264 processed images
Training loss: 1.0904157953519447
Validation loss: 0.5240527397164931
Validation accuracy: 0.8611111113658318
----
Processed 153 training batches with 4896 processed images
Training loss: 0.951746954540022
Validation loss: 0.5237487351092008
Validation accuracy: 0.8466880344427549
----
Processed 204 training batches with 6528 processed images
Training loss: 0.8817604285683117
Validation loss: 0.4766901903427564
Validation accuracy: 0.8707264959812164
***************************
Epoch 13/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.2634195919130362
Validation loss: 0.5181282684206963
Validation accuracy: 0.864716880596601
----
Processed 102 training batches with 3264 processed images
Training loss: 0.9816550478047016
Validation loss: 0.48043013134827983
Validation accuracy: 0.8611111113658318
----
Processed 153 training batches with 4896 processed images
Training loss: 0.8681771260460996
Validation loss: 0.4684423976219617
Validation accuracy: 0.879139957519678
----
Processed 204 training batches with 6528 processed images
Training loss: 0.800271700410282
Validation loss: 0.5482052215016805
Validation accuracy: 0.8493589735948123
***************************
Epoch 14/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.3828559506173228
Validation loss: 0.5303916736291006
Validation accuracy: 0.849091880596601
----
Processed 102 training batches with 3264 processed images
Training loss: 1.0334655329877256
Validation loss: 0.488574546117049
Validation accuracy: 0.872863246844365
----
Processed 153 training batches with 4896 processed images
Training loss: 0.8894703329778185
Validation loss: 0.49299268137950164
Validation accuracy: 0.8695245729042933
----
Processed 204 training batches with 6528 processed images
Training loss: 0.8202651154030772
Validation loss: 0.4519690200686455
Validation accuracy: 0.8755341882889087
***************************
Epoch 15/15
----
Processed 51 training batches with 1632 processed images
Training loss: 1.190361199425716
Validation loss: 0.5471719629489459
Validation accuracy: 0.8406784190581396
----
Processed 102 training batches with 3264 processed images
Training loss: 0.9003225778247795
Validation loss: 0.4851069043462093
Validation accuracy: 0.8743322652119857
----
Processed 153 training batches with 4896 processed images
Training loss: 0.7936358060322556
Validation loss: 0.4542982383416249
Validation accuracy: 0.8899572652119857
----
Processed 204 training batches with 6528 processed images
Training loss: 0.7480002879804256
Validation loss: 0.4508375066977281
Validation accuracy: 0.8815438036735241
Start testing the model ...
----
Batch 1/26 - Test loss: 0.2910994589328766
Batch 1/26 - Test accuracy: 0.875
----
Batch 2/26 - Test loss: 0.8744147419929504
Batch 2/26 - Test accuracy: 0.71875
----
Batch 3/26 - Test loss: 0.9912404417991638
Batch 3/26 - Test accuracy: 0.78125
----
Batch 4/26 - Test loss: 0.19327756762504578
Batch 4/26 - Test accuracy: 0.96875
----
Batch 5/26 - Test loss: 0.8125326633453369
Batch 5/26 - Test accuracy: 0.8125
----
Batch 6/26 - Test loss: 0.18770532310009003
Batch 6/26 - Test accuracy: 0.90625
----
Batch 7/26 - Test loss: 1.670804738998413
Batch 7/26 - Test accuracy: 0.625
----
Batch 8/26 - Test loss: 0.45142972469329834
Batch 8/26 - Test accuracy: 0.875
----
Batch 9/26 - Test loss: 0.13640664517879486
Batch 9/26 - Test accuracy: 0.9375
----
Batch 10/26 - Test loss: 0.060949504375457764
Batch 10/26 - Test accuracy: 1.0
----
Batch 11/26 - Test loss: 1.1187210083007812
Batch 11/26 - Test accuracy: 0.6875
----
Batch 12/26 - Test loss: 0.16746434569358826
Batch 12/26 - Test accuracy: 0.9375
----
Batch 13/26 - Test loss: 0.3692805767059326
Batch 13/26 - Test accuracy: 0.90625
----
Batch 14/26 - Test loss: 0.15024004876613617
Batch 14/26 - Test accuracy: 0.96875
----
Batch 15/26 - Test loss: 0.4962408244609833
Batch 15/26 - Test accuracy: 0.84375
----
Batch 16/26 - Test loss: 0.4529505968093872
Batch 16/26 - Test accuracy: 0.90625
----
Batch 17/26 - Test loss: 0.5132248997688293
Batch 17/26 - Test accuracy: 0.84375
----
Batch 18/26 - Test loss: 0.08782968670129776
Batch 18/26 - Test accuracy: 0.9375
----
Batch 19/26 - Test loss: 0.10298618674278259
Batch 19/26 - Test accuracy: 0.96875
----
Batch 20/26 - Test loss: 0.30241507291793823
Batch 20/26 - Test accuracy: 0.9375
----
Batch 21/26 - Test loss: 0.36275601387023926
Batch 21/26 - Test accuracy: 0.90625
----
Batch 22/26 - Test loss: 0.3331702947616577
Batch 22/26 - Test accuracy: 0.90625
----
Batch 23/26 - Test loss: 0.6033547520637512
Batch 23/26 - Test accuracy: 0.71875
----
Batch 24/26 - Test loss: 0.9678826332092285
Batch 24/26 - Test accuracy: 0.71875
----
Batch 25/26 - Test loss: 0.6136671900749207
Batch 25/26 - Test accuracy: 0.84375
----
Batch 26/26 - Test loss: 1.1801621913909912
Batch 26/26 - Test accuracy: 0.6842105388641357
----
Processed batches: 26
Processed images: 819
Average test loss: 0.5189310435492259
Average test accuracy: 0.8544407899563129
Save the model and parameters to checkpoint ...
Checkpoint saved to /home/workspace/ImageClassifier/20210313-125121_vgg16_checkpoint.pth
Elapsed time in seconds:  3684.727485562